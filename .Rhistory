}
}
simulations_profit <- simulations_profit + current_profit
}
# mean net profit
simulations_profit/10000
print(paste0("Net Profit is $", round(simulations_profit,2), " which is ~ + $2.26 in every iteration"))
mean_profit <- 0
buying_price <- 100
simulations_profit <- 0
current_profit <- 0
sell_below_90 <- 90
sell_above_120 <- 120
for(m in 1:10000){
stock <- stock_price()
for (stock_cost in stock[1:30]) {
if (stock_cost <= 90 || stock_cost >= 120 || stock_cost == 30){
current_profit <- stock_cost - buying_price
break
}
}
simulations_profit <- simulations_profit + current_profit
}
# mean net profit
simulations_profit/10000
print(paste0("Net Profit is $", round(simulations_profit,2), " which is ~ + $2.26 in every iteration"))
mean_profit <- 0
buying_price <- 100
simulations_profit <- 0
current_profit <- 0
sell_below_90 <- 90
sell_above_120 <- 120
for(m in 1:10000){
stock <- stock_price()
for (stock_cost in stock[1:30]) {
if (stock_cost <= 90 || stock_cost >= 120 || stock_cost == 30){
current_profit <- stock_cost - buying_price
break
}
}
simulations_profit <- simulations_profit + current_profit
}
# mean net profit
simulations_profit/10000
print(paste0("Net Profit is $", round(simulations_profit,2), " which is ~ + $2.26 in every iteration"))
mean_profit <- 0
buying_price <- 100
simulations_profit <- 0
current_profit <- 0
sell_below_90 <- 90
sell_above_120 <- 120
for(m in 1:10000){
stock <- stock_price()
for (stock_cost in stock[1:30]) {
if (stock_cost <= 90 || stock_cost >= 120 || stock_cost == 30){
current_profit <- stock_cost - buying_price
break
}
}
simulations_profit <- simulations_profit + current_profit
}
# mean net profit
simulations_profit/10000
print(paste0("Net Profit is $", round(simulations_profit,2), " which is ~ + $2.26 in every iteration"))
mean_profit <- 0
buying_price <- 100
simulations_profit <- 0
current_profit <- 0
sell_below_90 <- 90
sell_above_120 <- 120
for(m in 1:10000){
stock <- stock_price()
for (stock_cost in stock[1:30]) {
if (stock_cost <= 90 || stock_cost >= 120 || stock_cost == 30){
current_profit <- stock_cost - buying_price
break
}
}
simulations_profit <- simulations_profit + current_profit
}
# mean net profit
simulations_profit/10000
print(paste0("Net Profit is $", round(simulations_profit,2), " which is ~ + $2.26 in every iteration"))
mean_profit <- 0
buying_price <- 100
simulations_profit <- 0
current_profit <- 0
sell_below_90 <- 90
sell_above_120 <- 120
for(m in 1:10000){
stock <- stock_price()
for (stock_cost in stock[1:30]) {
if (stock_cost <= 90 || stock_cost >= 120 || stock_cost == 30){
current_profit <- stock_cost - buying_price
break
}
}
simulations_profit <- simulations_profit + current_profit
}
# mean net profit
simulations_profit/10000
print(paste0("Net Profit is $", round(simulations_profit,2), " which is ~ + $2.26 in every iteration"))
mean_profit <- 0
buying_price <- 100
simulations_profit <- 0
current_profit <- 0
sell_below_90 <- 90
sell_above_120 <- 120
for(m in 1:10000){
stock <- stock_price()
for (stock_cost in stock[1:30]) {
if (stock_cost <= 90 || stock_cost >= 120 || stock_cost == 30){
current_profit <- stock_cost - buying_price
break
}
}
simulations_profit <- simulations_profit + current_profit
}
# mean net profit
simulations_profit/10000
print(paste0("Net Profit is $", round(simulations_profit,2), " which is ~ + $2.26 in every iteration"))
mean_profit <- 0
buying_price <- 100
simulations_profit <- 0
current_profit <- 0
sell_below_90 <- 90
sell_above_120 <- 120
for(m in 1:10000){
stock <- stock_price()
for (stock_cost in stock[1:30]) {
if (stock_cost <= 90 || stock_cost >= 120 || stock_cost == 30){
current_profit <- stock_cost - buying_price
break
}
}
simulations_profit <- simulations_profit + current_profit
}
# mean net profit
simulations_profit/10000
print(paste0("Net Profit is $", round(simulations_profit,2), " which is ~ + $2.26 in every iteration"))
library(tidyverse)
library(diamonds)
diamonds2
diamonds2
diamonds
diamonds2 <- diamonds %>%
filter(carat <= 2.5) %>%
mutate(lprice = log2(price), lcarat = log2(carat))
diamonds2 <- diamonds %>%
filter(carat <= 2.5) %>%
mutate(lprice = log2(price), lcarat = log2(carat))
diamonds2_train <- slice(diamonds2, 1:43152)
diamonds2_test <- slice(diamonds2,43153:)
diamonds2_test <- slice(diamonds2,43153:53940)
mod_diamond2 <- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds2)
mod_diamond2 <- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds2_train)
mod_diamond3 <- lm(depth+table+x+y+z+lcarat+color+cut+clarity,data=diamonds2_train)
diamonds2_train
mod_diamond3 <- lm(depth + table + x + y + z + lcarat + color + cut + clarity,data=diamonds2_train)
mod_diamond3 <- lm(lprice ~ depth + table + x + y + z + lcarat + color + cut + clarity,data=diamonds2_train)
library(tidyverse)
library(modelr)
library(rpart)
library(randomForest)
diamonds2 <- diamonds %>%
filter(carat <= 2.5) %>%
mutate(lprice = log2(price), lcarat = log2(carat))
diamonds2
# 1)
# Splitting the data into test and train
diamonds_train_indices <- sample(1:nrow(diamonds2),0.8*nrow(diamonds2))
diamonds_train <- diamonds2 %>% slice(diamonds_train_indices)
diamonds_test <- diamonds2 %>% slice(-diamonds_train_indices)
# Fit the mod_diamonds2 on diamonds2_train
mod_diamond2 <- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds_train)
# Fit the mod_diamonds3 on diamonds2_train
mod_diamond3 <- lm(lprice ~ depth + table + x + y + z + lcarat + color + cut + clarity,data=diamonds_train)
## add predictions to mod_diamond 2 and 3
######################################### INVERT THE LOG ###################################################
model_dia_2 <- diamonds2 %>%
add_predictions(mod_diamond2, "pred2")
rmse(mod_diamond2,diamonds_test) # 0.1925
model_dia_2 <- diamonds2 %>%
add_predictions(mod_diamond3, "pred3") %>% mutate(pred_price = pred3^2)
sqrt(mean((diamonds2_test$price - diamonds2_test$pred2)^2))
## add predictions to mod_diamond 2 and 3
model_dia_2 <- diamonds2 %>%
add_predictions(mod_diamond2, "pred2") %>% mutate(pred_price = pred2^2)
sqrt(mean((diamonds2_test$price - diamonds2_test$pred2)^2))
rmse(mod_diamond2,diamonds_test) # 0.1925
model_dia_2 <- diamonds2 %>%
add_predictions(mod_diamond3, "pred3") %>% mutate(pred_price = pred3^2)
rmse(mod_diamond3,diamonds_test) #0.1915
rmse(model_dia_2,diamonds_test) # 0.1911
## add predictions to mod_diamond 2 and 3
model_dia_2 <- diamonds2 %>%
add_predictions(mod_diamond2, "pred2") %>% mutate(pred_price = pred2^2) %>% rmse(mod_diamond2,diamonds_test) # 0.1911
## add predictions to mod_diamond 2 and 3
model_dia_2 <- diamonds2 %>%
add_predictions(mod_diamond2, "pred2") %>% mutate(pred_price = pred2^2) %>% rmse(diamonds2,diamonds_test) # 0.1911
# Fit the mod_diamonds2 on diamonds_train
mod_diamond2 <- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds_train)
# Fit the mod_diamonds3 on diamonds_train
mod_diamond3 <- lm(lprice ~ depth + table + x + y + z + lcarat + color + cut + clarity,data=diamonds_train)
## add predictions to mod_diamond 2 and 3
model_dia_2 <- diamonds2 %>%
add_predictions(mod_diamond2, "pred2") %>% mutate(pred_price = pred2^2)
rmse(mod_diamond2,diamonds_test) # 0.1911
mod_diamond2
diamonds2
model_dia_2
sqrt(mean((model_dia_2$price - model_dia_2$pred_price)^2))
rmse(mod_diamond2,model_dia_2) # 0.1911
rmse(model_dia_2,diamonds_test) # 0.1911
model_dia_3 <- diamonds2 %>%
add_predictions(mod_diamond3, "pred3") %>% mutate(pred_price = pred3^2)
# rmse
sqrt(mean((model_dia_3$price - model_dia_3$pred_price)^2))
# random forest model on the same formula as the other trees
mod_diamond_rf <- randomForest(price ~ depth + table + x + y + z + lcarat + color + cut + clarity,
data = diamonds2, ntree = 200,
importance = TRUE, do.trace = 10)
# clarity > color > depth > cut > carat
importance(mod_diamond_rf)[order(importance(mod_diamond_rf)[,1], decreasing = TRUE),]
# random forest model on the same formula as the other trees
mod_diamond_rf <- randomForest(price ~ depth + table + x + y + z + lcarat + color + cut + clarity,
data = diamonds_train, ntree = 200,
importance = TRUE, do.trace = 10)
importance(mod_diamond_rf)[order(importance(mod_diamond_rf)[,1], decreasing = TRUE),]
# As the model gets more complicated the rmse increases because it is overfitting
rmse(regression_mod,diamonds2_test) ## 828.63
# Fit a regression tree using rpart
(regression_mod <- rpart(price ~ depth + table + x + y + z + lcarat + color + cut + clarity,data=diamonds_train))
# lcarat and y are the most important, with color being the least important
summary(regression_mod)
# As the model gets more complicated the rmse increases because it is overfitting
rmse(regression_mod,diamonds2_test) ## 828.63
# rmse
sqrt(mean((model_dia_3$price - model_dia_3$pred_price)^2))
library(tidyverse)
library(modelr)
library(rpart)
library(randomForest)
diamonds2 <- diamonds %>%
filter(carat <= 2.5) %>%
mutate(lprice = log2(price), lcarat = log2(carat))
# Splitting the data into test and train
diamonds_train_indices <- sample(1:nrow(diamonds2),0.8*nrow(diamonds2))
diamonds_train <- diamonds2 %>% slice(diamonds_train_indices)
diamonds_test <- diamonds2 %>% slice(-diamonds_train_indices)
# Fit the mod_diamonds2 on diamonds_train
mod_diamond2 <- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds_train)
# Fit the mod_diamonds3 on diamonds_train
mod_diamond3 <- lm(lprice ~ depth + table + x + y + z + lcarat + color + cut + clarity,data=diamonds_train)
## add predictions to mod_diamond 2 and 3
model_dia_2 <- diamonds2 %>%
add_predictions(mod_diamond2, "pred2") %>% mutate(pred_price = pred2^2)
# rmse
sqrt(mean((model_dia_2$price - model_dia_2$pred_price)^2))
# Fit a regression tree using rpart
(regression_mod <- rpart(price ~ depth + table + x + y + z + lcarat + color + cut + clarity,data=diamonds_train))
diamonds2 <- diamonds %>%
filter(carat <= 2.5) %>%
mutate(lprice = log2(price), lcarat = log2(carat))
# 1)
# Splitting the data into test and train
diamonds_train_indices <- sample(1:nrow(diamonds2),0.8*nrow(diamonds2))
diamonds_train <- diamonds2 %>% slice(diamonds_train_indices)
diamonds_test <- diamonds2 %>% slice(-diamonds_train_indices)
# Fit the mod_diamonds2 on diamonds_train
mod_diamond2 <- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds_train)
# Fit the mod_diamonds3 on diamonds_train
mod_diamond3 <- lm(lprice ~ depth + table + x + y + z + lcarat + color + cut + clarity,data=diamonds_train)
## add predictions to mod_diamond 2 and 3
model_dia_2 <- diamonds2 %>%
add_predictions(mod_diamond2, "pred2") %>% mutate(pred_price = pred2^2)
# rmse
sqrt(mean((model_dia_2$price - model_dia_2$pred_price)^2))
model_dia_3 <- diamonds2 %>%
add_predictions(mod_diamond3, "pred3") %>% mutate(pred_price = pred3^2)
# rmse
sqrt(mean((model_dia_3$price - model_dia_3$pred_price)^2))
# 2)
# Fit a regression tree using rpart
(regression_mod <- rpart(price ~ depth + table + x + y + z + lcarat + color + cut + clarity,data=diamonds_train))
# lcarat and y are the most important, with color being the least important
summary(regression_mod)
# As the model gets more complicated the rmse increases because it is overfitting
rmse(regression_mod,diamonds2_test) ## ~ 828.63
# 3)
# As the model gets more complicated the rmse increases because it is overfitting
rmse(regression_mod,diamonds_test) ## ~ 828.63
knitr::opts_chunk$set(echo = TRUE , dev = "png", dpi=300)
options(digits = 2)
library(readr)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(stringr)
library(ggrepel)
library(reshape2)
library(corrgram)
library(tree)
library(rpart)
library(rpart.plot)
library(randomForest)
library(plotly)
set.seed(51)
setwd("~/Documents/Github/UberDataAnalysis")
knitr::opts_chunk$set(echo = TRUE , dev = "png", dpi=300)
options(digits = 2)
library(readr)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(stringr)
library(ggrepel)
library(reshape2)
library(corrgram)
library(tree)
library(rpart)
library(rpart.plot)
library(randomForest)
library(plotly)
library(modelr)
IMDB <- read.csv("IMDM_ratings.csv")
imdb <- IMDB[!duplicated(IMDB), ]
imdb <- imdb[!is.na(imdb$gross), ]
imdb <- imdb[!is.na(imdb$budget), ]
imdb <- subset(imdb, select = -c(aspect_ratio))
imdb <- subset(imdb, select = -c(color))
imdb <- subset(imdb, select = -c(movie_imdb_link))
imdb <- subset(imdb, select = -c(language))
# Cleaning the movie title by removing the special character "Â" at the end and some whitespaces.
imdb$movie_title <- gsub("Â", "", as.character(factor(imdb$movie_title)))
clean_title <- str_trim(imdb$movie_title, side = "right")
# Adding profit and ROI
imdb <- imdb %>% mutate(net_profit = gross - budget,return_on_investment = (net_profit/budget)*100)
# replacing all NA's with col average
imdb$facenumber_in_poster[is.na(imdb$facenumber_in_poster)] <- round(mean(imdb$facenumber_in_poster, na.rm = TRUE))
# replacing all 0's with NA's
imdb[,c(5,6,8,13,24,26)][imdb[,c(5,6,8,13,24,26)] == 0] <- NA
# replacing all NA's with col average
imdb$num_critic_for_reviews[is.na(imdb$num_critic_for_reviews)] <- round(mean(imdb$num_critic_for_reviews, na.rm = TRUE))
imdb$duration[is.na(imdb$duration)] <- round(mean(imdb$duration, na.rm = TRUE))
imdb$director_facebook_likes[is.na(imdb$director_facebook_likes)] <- round(mean(imdb$director_facebook_likes, na.rm = TRUE))
imdb$actor_3_facebook_likes[is.na(imdb$actor_3_facebook_likes)] <- round(mean(imdb$actor_3_facebook_likes, na.rm = TRUE))
imdb$actor_1_facebook_likes[is.na(imdb$actor_1_facebook_likes)] <- round(mean(imdb$actor_1_facebook_likes, na.rm = TRUE))
imdb$cast_total_facebook_likes[is.na(imdb$cast_total_facebook_likes)] <- round(mean(imdb$cast_total_facebook_likes, na.rm = TRUE))
imdb$actor_2_facebook_likes[is.na(imdb$actor_2_facebook_likes)] <- round(mean(imdb$actor_2_facebook_likes, na.rm = TRUE))
imdb$movie_facebook_likes[is.na(imdb$movie_facebook_likes)] <- round(mean(imdb$movie_facebook_likes, na.rm = TRUE))
# delete the blank cols in content rating as they cannot be replaced with anything reasonable
imdb <- imdb[!(imdb$content_rating %in% ""),]
# replacing all content_rating with mordern rating system
imdb$content_rating[imdb$content_rating == 'M']   <- 'PG'
imdb$content_rating[imdb$content_rating == 'GP']  <- 'PG'
imdb$content_rating[imdb$content_rating == 'X']   <- 'NC-17'
imdb$content_rating[imdb$content_rating == 'Approved']  <- 'R'
imdb$content_rating[imdb$content_rating == 'Not Rated'] <- 'R'
imdb$content_rating[imdb$content_rating == 'Passed']    <- 'R'
imdb$content_rating[imdb$content_rating == 'Unrated']   <- 'R'
imdb$content_rating <- factor(imdb$content_rating)
levels(imdb$country) <- c(levels(imdb$country), "Others")
imdb$country[(imdb$country != 'USA')&(imdb$country != 'UK')] <- 'Others'
imdb$country <- factor(imdb$country)
ggplot(aes(x=imdb_score), data = imdb) +
geom_histogram(binwidth = 0.2,aes(fill = ..count..),colour="white",fill="#DAA520") +
scale_x_continuous(breaks = 0:10) +
ggtitle("IMDB Score Distribution") +
labs(x = "IMDB Score", y = "Count of Movies")
imdb %>% group_by(imdb_score) %>% filter(imdb_score > 7.5) %>% count(imdb_score) %>% arrange(desc(n))
rating_imdb <- imdb %>% group_by(content_rating) %>%
filter(!is.na(content_rating)) %>%
summarise(average_imdb_score = mean(imdb_score), num = n())
ggplot(aes(x=average_imdb_score, y = num, label = content_rating),data = rating_imdb) +
geom_point(color="#DAA520") +
geom_label_repel() +
ggtitle("Average IMDB Score by Rating") +
labs(x = "Average IMDB Score", y = "Count of Movies")
imdb.directors <- data.frame (imdb %>%
group_by(director_name) %>%
summarise(count = n())%>%
filter(count >10, count <50))
ggplot(aes(x = director_name, y = count), data = imdb.directors)+
geom_jitter(color="#DAA520") +
theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) +
labs(title="Directors Distribution on Movies",x="Directors",y="Count of Movies")
avg_score_per_director <- data.frame (imdb %>%
group_by(director_name) %>%
mutate(count = n(),average_imdb_score = mean(imdb_score))%>%
filter(count >14, count <50))
ggplot(aes(x = director_name, y = average_imdb_score), data = avg_score_per_director)+
geom_point(color="#DAA520") +
theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) +
labs(title="Average Imdb Score by Director",x="Directors",y="Average Imdb Score")
director_group <- group_by(imdb, director_name, num_user_for_reviews)
movie_by_director <- summarise(director_group,
mean_score = mean(imdb_score))
movie_by_director <- movie_by_director[67:4530,]
movie_by_director <- movie_by_director[with(movie_by_director, order(-mean_score)), ]
movie_by_director <- head(movie_by_director, 20)
ggplot(aes(x = mean_score, y = director_name), data = movie_by_director) +
geom_point(aes(color = num_user_for_reviews, fill="#f3ce13"), size = 2) + xlab("Average IMDB Score") +
ylab("Director Name")+ theme_minimal() + ggtitle('Director, User Reviews & Scores') +
scale_color_gradient(low = "yellow", high = "gold4")
user <- filter(imdb,num_user_for_reviews <= 3000)
ggplot(data = user, mapping = aes(x = imdb_score, y = num_user_for_reviews)) + geom_point(color="#DAA520") + facet_wrap( ~ country)+
xlab("IMDB Score") +
ylab("Number of User Reviews")+ theme_minimal() + ggtitle('Number of User Reviews by Country')
ggplot(imdb, aes(x =imdb_score, y =duration,colour = factor(imdb_score)))+
geom_point() +
labs(title = "Movie Duration and IMDB score",
x = "Imdb Score", y = "Duration")
ggplot(aes(x = imdb_score, y=net_profit/1000000 ), data = subset(imdb, net_profit > 1, !is.na(net_profit))) +
geom_jitter(shape = 21, fill = '#f3ce13') +
geom_smooth() +
labs(title = "Net Profit and IMDB score",
x = " Imdb Score", y = "Net Profit in $ Million")
imdb_train_indices <- sample(1:nrow(imdb),0.8*nrow(imdb))
imdb_train <- imdb %>% slice(imdb_train_indices)
imdb_test <- imdb %>% slice(-imdb_train_indices)
# How is imdb score related to the num of voted users compared to duration
imdb_mod_1 = lm (imdb_score~ duration + num_voted_users + num_critic_for_reviews + movie_facebook_likes,data=imdb_train)
summary(imdb_mod_1)
rmse(imdb_mod_1, imdb_test)
imdb_rf <-  randomForest(imdb_score ~ ., data=imdb_train,ntree = 500, importance = TRUE, do.trace = 50)
importance <- importance(imdb_rf)
varImportance <- data.frame(Variables = row.names(importance),
Importance = round(importance[ ,'IncNodePurity'],2))
# Create a rank variable based on importance
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance))))
# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance),
y = Importance, fill = Importance)) +
geom_bar(stat='identity', fill = "#DAA520") +
geom_text(aes(x = Variables, y = 0.5, label = Rank),
hjust=0, vjust=0.55, size = 4, colour = 'black') +
labs(x = 'Variables') +
coord_flip() + labs(title = "Variables by importance",
x = "Importance", y = "Variables")
imdb_select_rf <-  randomForest(imdb_score ~ ., data=imdb_train,ntree = 500, importance = TRUE, do.trace = 50)
rmse(imdb_rf, imdb_test)
predicted.rf = predict(imdb_select_rf,newdata=validation)
predicted.rf = predict(imdb_select_rf,newdata=imdb_test)
sum((imdb_test$imdb_score - predicted.rf)^2, na.rm=T)
rmse(imdb_rf, imdb_test)
imdb.rf <- randomForest(imdb_score~num_critic_for_reviews + duration + director_facebook_likes + actor_3_facebook_likes + actor_1_facebook_likes + gross + num_voted_users + cast_total_facebook_likes  + num_user_for_reviews + budget + title_year + actor_2_facebook_likes + movie_facebook_likes, data = imdb_train, mtry = 5)
predict.imdb.rf <- predict(imdb.rf, imdb_test)
sqrt((sum((imdb_test$imdb_score - predict.imdb.rf)^2))/ nrow(imdb_test))
varImpPlot(imdb.rf)
varImpPlot(imdb.rf) + labs(title = "Variables by importance",
x = "Importance")
varImpPlot(imdb.rf) + labs(title = "Variables by importance")
varImpPlot(imdb.rf)
predict.imdb.rf
#RMSE
sqrt((sum((imdb_test$imdb_score - predict.imdb.rf)^2))/ nrow(imdb_test))
# Calculating the mean squared error
sum((imdb_test$imdb_score - predicted.rf)^2, na.rm=T)
# Predicting using the new model
predicted.rf = predict(imdb_rf,imdb_test)
# Calculating the mean squared error
sum((imdb_test$imdb_score - predicted.rf)^2, na.rm=T)
sqrt((sum((imdb_test$imdb_score - predicted.rf)^2))/ nrow(imdb_test))
# Calculating the root mean sqaured error
rmse(imdb_rf, imdb_test)
#MSE
mean((predict.imdb.rf - imdb_test$imdb_score)^2)
#MSE
mean((predicted.rf - imdb_test$imdb_score)^2)
#MSE
mean((predict.imdb.rf - imdb_test$imdb_score)^2)
The mean squared error of the model below is `mean((predict.imdb.rf - imdb_test$imdb_score)^2)` which is lower than the previous model `mean((predicted.rf - imdb_test$imdb_score)^2)`.
#MSE
mean((predicted.rf - imdb_test$imdb_score)^2)
# Predicting using the new model
predicted.rf = predict(imdb_rf,imdb_test)
# Calculating the root mean squared error
sqrt((sum((imdb_test$imdb_score - predicted.rf)^2))/ nrow(imdb_test))
#MSE
mean((predicted.rf - imdb_test$imdb_score)^2)
imdb.rf <- randomForest(imdb_score~num_critic_for_reviews + duration + director_facebook_likes + actor_3_facebook_likes + actor_1_facebook_likes + gross + num_voted_users + cast_total_facebook_likes  + num_user_for_reviews + budget + title_year + actor_2_facebook_likes + movie_facebook_likes, data = imdb_train, mtry = 5)
#predict on test set
predict.imdb.rf <- predict(imdb.rf, imdb_test)
#RMSE
sqrt((sum((imdb_test$imdb_score - predict.imdb.rf)^2))/ nrow(imdb_test))
#MSE
mean((predict.imdb.rf - imdb_test$imdb_score)^2)
varImpPlot(imdb.rf)
confusionMatrix(predict.imdb.rf, imdb_test$imdb_score)
install.packages('caret')
install.packages("caret")
install.packages("caret")
library(caret)
library(ggplot2)
confusionMatrix(predict.imdb.rf, imdb_test$imdb_score)
library(lattice)
confusionMatrix(predict.imdb.rf, imdb_test$imdb_score)
library(caret)
install.packages('caret')
library(caret)
confusionMatrix(predict.imdb.rf, imdb_test$imdb_score)
library(caret)
install.packages("caret", dependencies = c("Depends", "Suggests"))
confusionMatrix(predict.imdb.rf, imdb_test$imdb_score)
caret::confusionMatrix(predict.imdb.rf, imdb_test$imdb_score)
install.packages("Rcpp")
install.packages(c("backports", "broom", "callr", "cli", "clipr", "codetools", "colorspace", "cpp11", "dbplyr", "digest", "ggrepel", "isoband", "jsonlite", "KernSmooth", "knitr", "labeling", "lubridate", "magrittr", "MASS", "mgcv", "nlme", "openssl", "pillar", "pkgbuild", "processx", "ps", "quantmod", "R6", "readr", "rlang", "rmarkdown", "rprojroot", "rstudioapi", "stringi", "survival", "tibble", "tinytex", "tseries", "vctrs", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "cli", "clipr", "codetools", "colorspace", "cpp11", "dbplyr", "digest", "ggrepel", "isoband", "jsonlite", "KernSmooth", "knitr", "labeling", "lubridate", "magrittr", "MASS", "mgcv", "nlme", "openssl", "pillar", "pkgbuild", "processx", "ps", "quantmod", "R6", "readr", "rlang", "rmarkdown", "rprojroot", "rstudioapi", "stringi", "survival", "tibble", "tinytex", "tseries", "vctrs", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "cli", "clipr", "codetools", "colorspace", "cpp11", "dbplyr", "digest", "ggrepel", "isoband", "jsonlite", "KernSmooth", "knitr", "labeling", "lubridate", "magrittr", "MASS", "mgcv", "nlme", "openssl", "pillar", "pkgbuild", "processx", "ps", "quantmod", "R6", "readr", "rlang", "rmarkdown", "rprojroot", "rstudioapi", "stringi", "survival", "tibble", "tinytex", "tseries", "vctrs", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "cli", "clipr", "codetools", "colorspace", "cpp11", "dbplyr", "digest", "ggrepel", "isoband", "jsonlite", "KernSmooth", "knitr", "labeling", "lubridate", "magrittr", "MASS", "mgcv", "nlme", "openssl", "pillar", "pkgbuild", "processx", "ps", "quantmod", "R6", "readr", "rlang", "rmarkdown", "rprojroot", "rstudioapi", "stringi", "survival", "tibble", "tinytex", "tseries", "vctrs", "withr", "xfun"))
